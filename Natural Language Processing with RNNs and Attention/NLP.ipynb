{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t860gY2V9Yu"
      },
      "source": [
        "# Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwtYTnElWAtJ",
        "outputId": "3f4683fa-62ae-4eb9-8b70-a18ea66d1fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Download Shakespeare's works\n",
        "shakespeare_url = \"https://homl.info/shakespeare\"\n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "\n",
        "# Read the file\n",
        "with open(filepath, 'r') as f:\n",
        "    shakespeare_text = f.read()\n",
        "\n",
        "# Encode text as characters using TextVectorization\n",
        "text_vec_layer = tf.keras.layers.TextVectorization(\n",
        "    split=\"character\",\n",
        "    standardize=\"lower\"\n",
        ")\n",
        "text_vec_layer.adapt([shakespeare_text])\n",
        "\n",
        "# Convert text to integer encoding\n",
        "encoded = text_vec_layer([shakespeare_text])[0]\n",
        "\n",
        "# Adjust encoding to exclude padding and unknown tokens\n",
        "encoded -= 2  # Remove <PAD> and <UNK>\n",
        "n_tokens = text_vec_layer.vocabulary_size() - 2  # Number of unique tokens\n",
        "dataset_size = len(encoded)  # Total characters in the text\n",
        "\n",
        "# Function to convert text sequence into input-target pairs\n",
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
        "\n",
        "# Split dataset into training, validation, and test sets\n",
        "length = 100\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True, seed=42)\n",
        "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
        "test_set = to_dataset(encoded[1_060_000:], length=length)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-t0TGXTWLP9"
      },
      "source": [
        "# Building and Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0OKW9rmWM4i"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"nadam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV_yTXD9WaEh",
        "outputId": "21383c4c-e76c-47b2-e9c4-29c3b8c460a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  28790/Unknown \u001b[1m3912s\u001b[0m 135ms/step - accuracy: 0.5420 - loss: 1.5190"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"my_shakespeare_model.keras\",  # Updated to include .keras extension\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_set,\n",
        "    validation_data=valid_set,\n",
        "    epochs=10,\n",
        "    callbacks=[model_ckpt]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScfZA7-JW1yP"
      },
      "source": [
        "# Wrapping the Model with Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDsyLO6cW4Aa"
      },
      "outputs": [],
      "source": [
        "# Wrap preprocessing into the model\n",
        "shakespeare_model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Lambda(lambda X: X - 2),  # Adjust encoding\n",
        "    model\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s39uD0BnXAVt"
      },
      "source": [
        "#  Generating Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya_gKAsiXCB7"
      },
      "outputs": [],
      "source": [
        "# Predict the next character\n",
        "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0, -1]\n",
        "y_pred = tf.argmax(y_proba)\n",
        "predicted_char = text_vec_layer.get_vocabulary()[y_pred + 2]\n",
        "\n",
        "print(f\"Predicted next character: {predicted_char}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPG-r_WLY7OR"
      },
      "source": [
        "# Generating Fake Shakespearean Text\n",
        "To generate Shakespearean-like text using a character-level RNN model, we can predict characters sequentially.\n",
        "\n",
        "## Decoding Strategies\n",
        "Greedy Decoding: Predict the most likely character at each step, but it often leads to repetitive outputs.\n",
        "### Random Sampling:\n",
        "Use tf.random.categorical() to sample the next character based on probabilities. This adds diversity to the generated text.\n",
        "Implementation\n",
        "1. Random Sampling with Temperature\n",
        "Adjusting the temperature controls the diversity of generated text:\n",
        "\n",
        "Low temperature: Favors high-probability characters (precise, rigid text).\n",
        "High temperature: Encourages diversity (creative, diverse text)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n28fcGPZE5F"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def next_char(text, temperature=1):\n",
        "    # Predict probabilities for the next character\n",
        "    y_proba = shakespeare_model.predict([text])[0, -1:]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature  # Rescale logits by temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]  # Sample next char\n",
        "    return text_vec_layer.get_vocabulary()[char_id + 2]  # Convert ID to char\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RiReO9wZLnz"
      },
      "outputs": [],
      "source": [
        "# Text Extension\n",
        "def extend_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXTsMjGJZP7W"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Generate text with varying temperatures\n",
        "print(extend_text(\"To be or not to be\", temperature=0.01))  # Rigid, repetitive text\n",
        "print(extend_text(\"To be or not to be\", temperature=1))     # Balanced, diverse text\n",
        "print(extend_text(\"To be or not to be\", temperature=100))   # Random, chaotic text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk-t9Hj9ZcPs"
      },
      "source": [
        "# Stateful RNNs\n",
        "\n",
        "A stateful RNN preserves its hidden state across training batches, enabling it to learn longer-term dependencies.\n",
        "\n",
        "## Data Preparation for Stateful RNNs\n",
        "Ensure sequences in the same batch are consecutive across batches. Use a custom function to create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ebFL6J-ZhJR"
      },
      "outputs": [],
      "source": [
        "def to_dataset_for_stateful_rnn(sequence, length):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda window: window.batch(length + 1)).batch(1)  # Batch size = 1\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
        "\n",
        "# Prepare datasets\n",
        "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length)\n",
        "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000], length)\n",
        "stateful_test_set = to_dataset_for_stateful_rnn(encoded[1_060_000:], length)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U53MweRpZonk"
      },
      "source": [
        "# Stateful RNN Model\n",
        "Define the model and include the stateful=True parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxcdAQc5Zq0_"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16, batch_input_shape=[1, None]),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMWRj6niZwNv"
      },
      "source": [
        "# Reset States Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzj1eyA0ZyYO"
      },
      "outputs": [],
      "source": [
        "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.model.reset_states()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw-hsTdfZ5ej"
      },
      "source": [
        "# Compile and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l778TyxOZ7gE"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(\n",
        "    stateful_train_set,\n",
        "    validation_data=stateful_valid_set,\n",
        "    epochs=10,\n",
        "    callbacks=[ResetStatesCallback(), model_ckpt]\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}