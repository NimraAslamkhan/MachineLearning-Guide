{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Artificial Neural Networks with Keras\n"
      ],
      "metadata": {
        "id": "eTfV1QtCUs5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceptron classifier to properly interpret the binary labels and output the predictions for the new samples"
      ],
      "metadata": {
        "id": "4dGwYmC4VWZg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cekwMypNUh_j",
        "outputId": "4abaedab-1a7c-4ffa-d46a-fb4e1399a1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris(as_frame=True)\n",
        "\n",
        "# Use petal length and petal width as features\n",
        "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "\n",
        "# Create a binary target variable: True for Iris setosa, False otherwise\n",
        "y = (iris.target == 0).astype(int)  # Ensures y is binary (0 or 1)\n",
        "\n",
        "# Initialize and fit the Perceptron model\n",
        "per_clf = Perceptron(random_state=42)\n",
        "per_clf.fit(X, y)\n",
        "\n",
        "# New sample data to predict\n",
        "X_new = [[2, 0.5], [3, 1]]\n",
        "y_pred = per_clf.predict(X_new)\n",
        "\n",
        "print(\"Predictions:\", y_pred)  # Should output 1 and 0 (True and False) for these samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation and Adjustments\n",
        "### Activation Function:\n",
        " For a regression problem like predicting housing prices, the MLPRegressor by default does not apply any activation function to the output layer, which allows it to predict any real value. This is correct for this case.\n",
        "\n",
        "### Improvement in Code Structure:\n",
        "It's good practice to separate training, validation, and testing data clearly. Your code already does this properly, but I will make sure everything is explained and organized correctly.\n",
        "\n",
        "### Optional - Tuning the Model:\n",
        "The model may benefit from tuning the number of layers, hidden units, or learning rate, though you're using a reasonable setup here"
      ],
      "metadata": {
        "id": "OfGDod50Vwk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Fetch the California housing dataset\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state=42)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "# Initialize the MLP Regressor with 3 hidden layers of 50 units each\n",
        "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
        "\n",
        "# Create a pipeline with StandardScaler for preprocessing and MLPRegressor\n",
        "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
        "\n",
        "# Train the model using the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation data\n",
        "y_pred = pipeline.predict(X_valid)\n",
        "\n",
        "# Calculate RMSE (Root Mean Squared Error) to evaluate performance\n",
        "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "\n",
        "# Output the RMSE result\n",
        "print(f\"Validation RMSE: {rmse:.3f}\")  # e.g., about 0.505\n",
        "\n",
        "# Optional: Evaluate the model on the test set\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
        "print(f\"Test RMSE: {test_rmse:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C79sEY4dVZgv",
        "outputId": "4b32befd-364c-4030-cb89-f168a2853b62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE: 0.505\n",
            "Test RMSE: 0.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading and training a neural network on the Fashion MNIST dataset using Keras, TensorFlow, and Python."
      ],
      "metadata": {
        "id": "-lQKQL6IW9yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
        "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
        "\n",
        "# Normalize the pixel values by scaling them to [0, 1] range\n",
        "X_train, X_valid, X_test = X_train / 255.0, X_valid / 255.0, X_test / 255.0\n",
        "\n",
        "# Define the class names for Fashion MNIST\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgPyiVthXGTH",
        "outputId": "b0eab3f9-0e55-4e88-f0af-77f9fa067cad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Sequential model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),  # Flatten the input image\n",
        "    tf.keras.layers.Dense(300, activation=\"relu\"),  # First hidden layer with ReLU activation\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),  # Second hidden layer with ReLU activation\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")  # Output layer with softmax activation for multi-class classification\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcTcED7BXO74",
        "outputId": "9320f8be-8e82-40f0-9891-a46e186bb073"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with sparse categorical crossentropy loss function, SGD optimizer, and accuracy as a metric\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "pOOyXjNSXRAH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for 30 epochs with the training and validation data\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5oml6NEXU-s",
        "outputId": "4cb1048c-3317-48db-fb35-0aa5bd385cc8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6894 - loss: 0.9690 - val_accuracy: 0.8136 - val_loss: 0.5160\n",
            "Epoch 2/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.5014 - val_accuracy: 0.8412 - val_loss: 0.4383\n",
            "Epoch 3/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8451 - loss: 0.4404 - val_accuracy: 0.8488 - val_loss: 0.4158\n",
            "Epoch 4/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.4100 - val_accuracy: 0.8518 - val_loss: 0.4083\n",
            "Epoch 5/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8622 - loss: 0.3965 - val_accuracy: 0.8576 - val_loss: 0.3879\n",
            "Epoch 6/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.3773 - val_accuracy: 0.8646 - val_loss: 0.3718\n",
            "Epoch 7/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8707 - loss: 0.3635 - val_accuracy: 0.8674 - val_loss: 0.3672\n",
            "Epoch 8/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8764 - loss: 0.3517 - val_accuracy: 0.8694 - val_loss: 0.3680\n",
            "Epoch 9/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8774 - loss: 0.3450 - val_accuracy: 0.8732 - val_loss: 0.3572\n",
            "Epoch 10/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.3301 - val_accuracy: 0.8726 - val_loss: 0.3551\n",
            "Epoch 11/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.3235 - val_accuracy: 0.8770 - val_loss: 0.3467\n",
            "Epoch 12/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 0.3136 - val_accuracy: 0.8760 - val_loss: 0.3406\n",
            "Epoch 13/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8922 - loss: 0.3051 - val_accuracy: 0.8684 - val_loss: 0.3558\n",
            "Epoch 14/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8912 - loss: 0.3006 - val_accuracy: 0.8762 - val_loss: 0.3392\n",
            "Epoch 15/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8952 - loss: 0.2931 - val_accuracy: 0.8798 - val_loss: 0.3359\n",
            "Epoch 16/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8978 - loss: 0.2896 - val_accuracy: 0.8776 - val_loss: 0.3377\n",
            "Epoch 17/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8967 - loss: 0.2825 - val_accuracy: 0.8694 - val_loss: 0.3571\n",
            "Epoch 18/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9024 - loss: 0.2718 - val_accuracy: 0.8830 - val_loss: 0.3211\n",
            "Epoch 19/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9035 - loss: 0.2704 - val_accuracy: 0.8632 - val_loss: 0.3733\n",
            "Epoch 20/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.2663 - val_accuracy: 0.8830 - val_loss: 0.3263\n",
            "Epoch 21/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2589 - val_accuracy: 0.8814 - val_loss: 0.3216\n",
            "Epoch 22/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2532 - val_accuracy: 0.8810 - val_loss: 0.3296\n",
            "Epoch 23/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2495 - val_accuracy: 0.8862 - val_loss: 0.3141\n",
            "Epoch 24/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2436 - val_accuracy: 0.8824 - val_loss: 0.3232\n",
            "Epoch 25/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.2375 - val_accuracy: 0.8842 - val_loss: 0.3173\n",
            "Epoch 26/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2380 - val_accuracy: 0.8806 - val_loss: 0.3262\n",
            "Epoch 27/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2327 - val_accuracy: 0.8816 - val_loss: 0.3178\n",
            "Epoch 28/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2310 - val_accuracy: 0.8892 - val_loss: 0.3080\n",
            "Epoch 29/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9179 - loss: 0.2285 - val_accuracy: 0.8814 - val_loss: 0.3248\n",
            "Epoch 30/30\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2280 - val_accuracy: 0.8832 - val_loss: 0.3183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Plot the learning curves (loss and accuracy) over the epochs\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5), xlim=[0, 29], ylim=[0, 1], grid=True, xlabel=\"Epoch\", style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "tkVB0HBaXZeg",
        "outputId": "a296dfea-4448-430f-8064-865c5c732bcd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to make predictions on a few test instances\n",
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "\n",
        "# Display the predicted probabilities\n",
        "print(y_proba.round(2))\n",
        "\n",
        "# Get the class predictions based on the highest probability\n",
        "y_pred = y_proba.argmax(axis=-1)\n",
        "\n",
        "# Map the predicted class indices to class names\n",
        "print(np.array(class_names)[y_pred])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxBoOSF8XgHl",
        "outputId": "1d7afcae-908d-4f56-aedc-25036691e32e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "[[0.   0.   0.   0.   0.   0.03 0.   0.02 0.   0.95]\n",
            " [0.   0.   0.99 0.   0.01 0.   0.   0.   0.   0.  ]\n",
            " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
            "['Ankle boot' 'Pullover' 'Trouser']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model uses softmax on the output layer to handle multi-class classification.\n",
        "\n",
        "ReLU activation functions are used in the hidden layers, helping the model learn non-linear decision boundaries.\n",
        "\n",
        "The model is trained for 30 epochs, and the performance is evaluated using both loss and accuracy metrics.\n",
        "\n",
        "The predictions are made by calculating the probability distribution for each test image, and the argmax function is used to select the class with the highest probability.\n",
        "\n",
        "This approach works well for simple image classification tasks like Fashion MNIST, and you can tweak the architecture, optimizer, and training strategy for different results or more complex datasets"
      ],
      "metadata": {
        "id": "dWpZiIt3X124"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section describes how to build and train a deep neural network model in TensorFlow using the Keras API, focusing on some advanced techniques like normalization, multi-input models, auxiliary outputs, and saving/loading models. Below is a breakdown of the key concepts:\n",
        "\n",
        "1. Model Construction:\n",
        "Normalization Layer: A Normalization layer is used as the first layer in the model. It works similarly to StandardScaler in Scikit-Learn and must be fitted to the training data using the adapt() method before training the model.\n",
        "Sequential Model: A simple feedforward model is created with three hidden layers, each with 50 neurons and ReLU activation. The final output layer predicts a single continuous value.\n",
        "Optimizer: Adam optimizer with a learning rate of\n",
        "1\n",
        "×\n",
        "1\n",
        "0\n",
        "−\n",
        "3\n",
        "1×10\n",
        "−3\n",
        "  is used for optimization.\n",
        "2. Multiple Inputs (Wide and Deep Model):\n",
        "Wide and Deep Model: A common architecture that splits features into two parts:\n",
        "Wide Path: Uses shallow layers for quick feature extraction.\n",
        "Deep Path: Uses deeper layers to model complex relationships between features.\n",
        "Inputs: The model receives two sets of features: one for the \"wide\" path (first 5 features) and one for the \"deep\" path (features from index 2 to 7).\n",
        "3. Auxiliary Outputs:\n",
        "Additional Output: The model is extended with an auxiliary output to help regularize the model. This output is used as an additional task, usually for improving the main task’s performance.\n",
        "Loss Weights: When compiling the model, you can assign different weights to each output’s loss to prioritize the main task over the auxiliary task.\n",
        "4. Saving and Restoring Models:\n",
        "Saving a Model: A trained model can be saved in TensorFlow's format using model.save().\n",
        "Loading a Model: You can reload the saved model later using tf.keras.models.load_model() to make predictions or evaluate it again.\n",
        "5. Using Callbacks:\n",
        "ModelCheckpoint: Saves the model weights at regular intervals during training.\n",
        "EarlyStopping: Stops training early if the validation loss doesn’t improve, preventing overfitting.\n",
        "Custom Callback: Custom callbacks can be created to monitor specific metrics (e.g., printing the ratio of validation loss to training loss at the end of each epoch).\n",
        "TensorBoard: A callback that logs metrics for visualization using TensorBoard. It tracks various outputs such as scalars, histograms, images, and audio.\n",
        "6. TensorBoard for Visualization:\n",
        "Logging: You can use TensorBoard to visualize metrics, including loss curves and histograms, to analyze training performance.\n",
        "Profiling: TensorBoard can also be used to profile the model’s performance during training by monitoring specific operations.\n",
        "This section is particularly useful when you want to build a flexible and scalable model, such as those involving multiple feature sets, auxiliary tasks, and extensive training monitoring. You also learn how to save and resume model training, which is essential for real-world machine learning applications"
      ],
      "metadata": {
        "id": "DGxJ6cpjZpv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
        "norm_layer.adapt(X_train)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    norm_layer,\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
        "print(f\"Test MSE: {mse_test}\")\n",
        "print(f\"Test RMSE: {rmse_test}\")\n",
        "\n",
        "# Make predictions on new data\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)\n",
        "print(f\"Predictions: {y_pred}\")\n",
        "\n",
        "# Save the model (using the .keras extension for TensorFlow's SavedModel format)\n",
        "model.save(\"my_keras_model.keras\")\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model(\"my_keras_model.keras\")\n",
        "\n",
        "# Make predictions with the loaded model\n",
        "y_pred = loaded_model.predict(X_new)\n",
        "print(f\"Predictions from loaded model: {y_pred}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct3mEwzPXhAs",
        "outputId": "9beb578c-e9a2-4d9d-e31c-43209c924273"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - RootMeanSquaredError: 1.1796 - loss: 1.4656 - val_RootMeanSquaredError: 0.6886 - val_loss: 0.4742\n",
            "Epoch 2/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.6276 - loss: 0.3943 - val_RootMeanSquaredError: 0.6356 - val_loss: 0.4040\n",
            "Epoch 3/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - RootMeanSquaredError: 0.6011 - loss: 0.3626 - val_RootMeanSquaredError: 0.6175 - val_loss: 0.3813\n",
            "Epoch 4/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5867 - loss: 0.3444 - val_RootMeanSquaredError: 0.6272 - val_loss: 0.3933\n",
            "Epoch 5/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5672 - loss: 0.3219 - val_RootMeanSquaredError: 0.6074 - val_loss: 0.3689\n",
            "Epoch 6/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5682 - loss: 0.3230 - val_RootMeanSquaredError: 0.6213 - val_loss: 0.3860\n",
            "Epoch 7/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5603 - loss: 0.3141 - val_RootMeanSquaredError: 0.5827 - val_loss: 0.3395\n",
            "Epoch 8/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5577 - loss: 0.3111 - val_RootMeanSquaredError: 0.6374 - val_loss: 0.4062\n",
            "Epoch 9/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5508 - loss: 0.3037 - val_RootMeanSquaredError: 0.5830 - val_loss: 0.3399\n",
            "Epoch 10/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5454 - loss: 0.2976 - val_RootMeanSquaredError: 0.5749 - val_loss: 0.3305\n",
            "Epoch 11/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5484 - loss: 0.3008 - val_RootMeanSquaredError: 0.5655 - val_loss: 0.3198\n",
            "Epoch 12/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5327 - loss: 0.2839 - val_RootMeanSquaredError: 0.5714 - val_loss: 0.3264\n",
            "Epoch 13/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5257 - loss: 0.2765 - val_RootMeanSquaredError: 0.5500 - val_loss: 0.3025\n",
            "Epoch 14/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5235 - loss: 0.2743 - val_RootMeanSquaredError: 0.6760 - val_loss: 0.4569\n",
            "Epoch 15/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5267 - loss: 0.2775 - val_RootMeanSquaredError: 0.5537 - val_loss: 0.3066\n",
            "Epoch 16/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5160 - loss: 0.2664 - val_RootMeanSquaredError: 0.5746 - val_loss: 0.3302\n",
            "Epoch 17/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5231 - loss: 0.2736 - val_RootMeanSquaredError: 0.5692 - val_loss: 0.3240\n",
            "Epoch 18/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5203 - loss: 0.2708 - val_RootMeanSquaredError: 0.5591 - val_loss: 0.3126\n",
            "Epoch 19/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5088 - loss: 0.2590 - val_RootMeanSquaredError: 0.5594 - val_loss: 0.3130\n",
            "Epoch 20/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5182 - loss: 0.2686 - val_RootMeanSquaredError: 0.5813 - val_loss: 0.3379\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5406 - loss: 0.2924\n",
            "Test MSE: 0.2953549027442932\n",
            "Test RMSE: 0.5434656143188477\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Predictions: [[0.41618955]\n",
            " [1.287262  ]\n",
            " [4.76322   ]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Predictions from loaded model: [[0.41618955]\n",
            " [1.287262  ]\n",
            " [4.76322   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks for checkpoints and early stopping\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_checkpoints.weights.h5\", save_weights_only=True)\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "# Fit the model with callbacks\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n",
        "# Custom callback to display validation/train loss ratio\n",
        "class PrintValTrainRatioCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
        "        print(f\"Epoch={epoch}, val/train={ratio:.2f}\")\n",
        "\n",
        "# Fit with custom callback\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb, PrintValTrainRatioCallback()])\n",
        "\n",
        "# Setup TensorBoard callback\n",
        "from pathlib import Path\n",
        "from time import strftime\n",
        "\n",
        "def get_run_logdir(root_logdir=\"my_logs\"):\n",
        "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir, profile_batch=(100, 200))\n",
        "\n",
        "# Fit with TensorBoard callback\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[tensorboard_cb])\n",
        "\n",
        "# Example of logging custom scalar, histogram, image, text, and audio\n",
        "import numpy as np\n",
        "test_logdir = get_run_logdir()\n",
        "writer = tf.summary.create_file_writer(str(test_logdir))\n",
        "\n",
        "with writer.as_default():\n",
        "    for step in range(1, 1001):\n",
        "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
        "        data = (np.random.randn(100) + 2) * step / 100\n",
        "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
        "        images = np.random.rand(2, 32, 32, 3) * step / 1000\n",
        "        tf.summary.image(\"my_images\", images, step=step)\n",
        "        texts = [f\"The step is {step}\", f\"Its square is {step ** 2}\"]\n",
        "        tf.summary.text(\"my_text\", texts, step=step)\n",
        "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
        "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
        "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3ccc42Ua6mI",
        "outputId": "78801dfe-6f8b-45d1-c53d-010869887fca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4957 - loss: 0.2459 - val_RootMeanSquaredError: 0.5406 - val_loss: 0.2922\n",
            "Epoch 2/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4941 - loss: 0.2444 - val_RootMeanSquaredError: 0.5560 - val_loss: 0.3091\n",
            "Epoch 3/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4968 - loss: 0.2469 - val_RootMeanSquaredError: 0.5493 - val_loss: 0.3018\n",
            "Epoch 4/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.4973 - loss: 0.2475 - val_RootMeanSquaredError: 0.5399 - val_loss: 0.2915\n",
            "Epoch 5/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4952 - loss: 0.2454 - val_RootMeanSquaredError: 0.5459 - val_loss: 0.2980\n",
            "Epoch 6/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4942 - loss: 0.2444 - val_RootMeanSquaredError: 0.5483 - val_loss: 0.3007\n",
            "Epoch 7/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4965 - loss: 0.2466 - val_RootMeanSquaredError: 0.5517 - val_loss: 0.3044\n",
            "Epoch 8/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4904 - loss: 0.2407 - val_RootMeanSquaredError: 0.5484 - val_loss: 0.3007\n",
            "Epoch 9/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4960 - loss: 0.2461 - val_RootMeanSquaredError: 0.5331 - val_loss: 0.2842\n",
            "Epoch 10/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4939 - loss: 0.2440 - val_RootMeanSquaredError: 0.5331 - val_loss: 0.2842\n",
            "Epoch 11/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4989 - loss: 0.2490 - val_RootMeanSquaredError: 0.5396 - val_loss: 0.2912\n",
            "Epoch 12/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - RootMeanSquaredError: 0.4897 - loss: 0.2399 - val_RootMeanSquaredError: 0.5425 - val_loss: 0.2944\n",
            "Epoch 13/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.4893 - loss: 0.2395 - val_RootMeanSquaredError: 0.5444 - val_loss: 0.2963\n",
            "Epoch 14/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4836 - loss: 0.2340 - val_RootMeanSquaredError: 0.5318 - val_loss: 0.2828\n",
            "Epoch 15/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4801 - loss: 0.2307 - val_RootMeanSquaredError: 0.5353 - val_loss: 0.2866\n",
            "Epoch 16/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4956 - loss: 0.2458 - val_RootMeanSquaredError: 0.5424 - val_loss: 0.2942\n",
            "Epoch 17/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4732 - loss: 0.2240 - val_RootMeanSquaredError: 0.5372 - val_loss: 0.2885\n",
            "Epoch 18/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4716 - loss: 0.2225 - val_RootMeanSquaredError: 0.5584 - val_loss: 0.3118\n",
            "Epoch 19/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4869 - loss: 0.2371 - val_RootMeanSquaredError: 0.5439 - val_loss: 0.2958\n",
            "Epoch 20/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4826 - loss: 0.2329 - val_RootMeanSquaredError: 0.5572 - val_loss: 0.3105\n",
            "Epoch 1/20\n",
            "\u001b[1m409/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4946 - loss: 0.2449Epoch=0, val/train=1.25\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4945 - loss: 0.2448 - val_RootMeanSquaredError: 0.5448 - val_loss: 0.2969\n",
            "Epoch 2/20\n",
            "\u001b[1m407/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4896 - loss: 0.2397Epoch=1, val/train=1.21\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4895 - loss: 0.2396 - val_RootMeanSquaredError: 0.5320 - val_loss: 0.2830\n",
            "Epoch 3/20\n",
            "\u001b[1m407/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4756 - loss: 0.2263Epoch=2, val/train=1.25\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - RootMeanSquaredError: 0.4758 - loss: 0.2265 - val_RootMeanSquaredError: 0.5432 - val_loss: 0.2951\n",
            "Epoch 4/20\n",
            "\u001b[1m401/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4833 - loss: 0.2338Epoch=3, val/train=1.25\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4833 - loss: 0.2338 - val_RootMeanSquaredError: 0.5398 - val_loss: 0.2914\n",
            "Epoch 5/20\n",
            "\u001b[1m410/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4782 - loss: 0.2288Epoch=4, val/train=1.23\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4783 - loss: 0.2288 - val_RootMeanSquaredError: 0.5326 - val_loss: 0.2836\n",
            "Epoch 6/20\n",
            "\u001b[1m412/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4798 - loss: 0.2303Epoch=5, val/train=1.22\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4798 - loss: 0.2304 - val_RootMeanSquaredError: 0.5313 - val_loss: 0.2823\n",
            "Epoch 7/20\n",
            "\u001b[1m410/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4827 - loss: 0.2332Epoch=6, val/train=1.23\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4827 - loss: 0.2331 - val_RootMeanSquaredError: 0.5307 - val_loss: 0.2817\n",
            "Epoch 8/20\n",
            "\u001b[1m392/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4746 - loss: 0.2253Epoch=7, val/train=1.39\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4746 - loss: 0.2253 - val_RootMeanSquaredError: 0.5624 - val_loss: 0.3163\n",
            "Epoch 9/20\n",
            "\u001b[1m399/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4783 - loss: 0.2289Epoch=8, val/train=1.30\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4784 - loss: 0.2289 - val_RootMeanSquaredError: 0.5466 - val_loss: 0.2987\n",
            "Epoch 10/20\n",
            "\u001b[1m402/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4674 - loss: 0.2185Epoch=9, val/train=1.26\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4676 - loss: 0.2188 - val_RootMeanSquaredError: 0.5346 - val_loss: 0.2858\n",
            "Epoch 11/20\n",
            "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4734 - loss: 0.2241Epoch=10, val/train=1.24\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.4734 - loss: 0.2242 - val_RootMeanSquaredError: 0.5318 - val_loss: 0.2828\n",
            "Epoch 12/20\n",
            "\u001b[1m389/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4676 - loss: 0.2187Epoch=11, val/train=2.18\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4681 - loss: 0.2192 - val_RootMeanSquaredError: 0.7016 - val_loss: 0.4922\n",
            "Epoch 13/20\n",
            "\u001b[1m409/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4932 - loss: 0.2436Epoch=12, val/train=1.19\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4931 - loss: 0.2435 - val_RootMeanSquaredError: 0.5285 - val_loss: 0.2793\n",
            "Epoch 14/20\n",
            "\u001b[1m399/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4644 - loss: 0.2157Epoch=13, val/train=1.29\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4645 - loss: 0.2158 - val_RootMeanSquaredError: 0.5337 - val_loss: 0.2848\n",
            "Epoch 15/20\n",
            "\u001b[1m409/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4603 - loss: 0.2121Epoch=14, val/train=1.39\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4605 - loss: 0.2123 - val_RootMeanSquaredError: 0.5567 - val_loss: 0.3099\n",
            "Epoch 16/20\n",
            "\u001b[1m410/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4678 - loss: 0.2189Epoch=15, val/train=1.27\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4678 - loss: 0.2190 - val_RootMeanSquaredError: 0.5313 - val_loss: 0.2823\n",
            "Epoch 17/20\n",
            "\u001b[1m408/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4666 - loss: 0.2178Epoch=16, val/train=1.25\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4667 - loss: 0.2179 - val_RootMeanSquaredError: 0.5283 - val_loss: 0.2791\n",
            "Epoch 18/20\n",
            "\u001b[1m388/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4610 - loss: 0.2127Epoch=17, val/train=1.31\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.4614 - loss: 0.2131 - val_RootMeanSquaredError: 0.5367 - val_loss: 0.2880\n",
            "Epoch 19/20\n",
            "\u001b[1m398/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5966 - loss: 0.3623Epoch=18, val/train=5.49\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5942 - loss: 0.3593 - val_RootMeanSquaredError: 1.2464 - val_loss: 1.5535\n",
            "Epoch 20/20\n",
            "\u001b[1m403/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5964 - loss: 0.3640Epoch=19, val/train=1.07\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5947 - loss: 0.3620 - val_RootMeanSquaredError: 0.5538 - val_loss: 0.3067\n",
            "Epoch 1/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.4579 - loss: 0.2098 - val_RootMeanSquaredError: 0.5298 - val_loss: 0.2807\n",
            "Epoch 2/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4711 - loss: 0.2220 - val_RootMeanSquaredError: 0.5465 - val_loss: 0.2987\n",
            "Epoch 3/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4723 - loss: 0.2233 - val_RootMeanSquaredError: 0.5494 - val_loss: 0.3019\n",
            "Epoch 4/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4698 - loss: 0.2208 - val_RootMeanSquaredError: 0.5344 - val_loss: 0.2855\n",
            "Epoch 5/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4567 - loss: 0.2087 - val_RootMeanSquaredError: 0.5329 - val_loss: 0.2839\n",
            "Epoch 6/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4641 - loss: 0.2155 - val_RootMeanSquaredError: 0.5316 - val_loss: 0.2826\n",
            "Epoch 7/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4647 - loss: 0.2160 - val_RootMeanSquaredError: 0.5281 - val_loss: 0.2789\n",
            "Epoch 8/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4517 - loss: 0.2042 - val_RootMeanSquaredError: 0.5310 - val_loss: 0.2819\n",
            "Epoch 9/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.4559 - loss: 0.2081 - val_RootMeanSquaredError: 0.5333 - val_loss: 0.2844\n",
            "Epoch 10/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - RootMeanSquaredError: 0.4597 - loss: 0.2113 - val_RootMeanSquaredError: 0.5263 - val_loss: 0.2770\n",
            "Epoch 11/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4672 - loss: 0.2184 - val_RootMeanSquaredError: 0.5327 - val_loss: 0.2838\n",
            "Epoch 12/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4553 - loss: 0.2075 - val_RootMeanSquaredError: 0.5362 - val_loss: 0.2875\n",
            "Epoch 13/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4567 - loss: 0.2086 - val_RootMeanSquaredError: 0.5247 - val_loss: 0.2753\n",
            "Epoch 14/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4514 - loss: 0.2038 - val_RootMeanSquaredError: 0.5623 - val_loss: 0.3162\n",
            "Epoch 15/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4535 - loss: 0.2058 - val_RootMeanSquaredError: 0.5408 - val_loss: 0.2925\n",
            "Epoch 16/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4593 - loss: 0.2112 - val_RootMeanSquaredError: 0.5394 - val_loss: 0.2910\n",
            "Epoch 17/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4490 - loss: 0.2017 - val_RootMeanSquaredError: 0.5832 - val_loss: 0.3401\n",
            "Epoch 18/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - RootMeanSquaredError: 0.4439 - loss: 0.1972 - val_RootMeanSquaredError: 0.5326 - val_loss: 0.2837\n",
            "Epoch 19/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4548 - loss: 0.2070 - val_RootMeanSquaredError: 0.5312 - val_loss: 0.2822\n",
            "Epoch 20/20\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.4575 - loss: 0.2095 - val_RootMeanSquaredError: 0.5356 - val_loss: 0.2869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load and preprocess the MNIST data\n",
        "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()\n",
        "\n",
        "# Reshape the data to be (num_samples, 28, 28, 1) as the model expects\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "X_valid = X_valid.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "# Define the model-building function\n",
        "def build_model(hp):\n",
        "    # Hyperparameters\n",
        "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
        "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
        "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "    optimizer_choice = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
        "\n",
        "    # Define optimizer\n",
        "    if optimizer_choice == \"sgd\":\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Build the model\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(28, 28, 1)))  # Input layer with correct shape for MNIST\n",
        "    model.add(tf.keras.layers.Flatten())  # Flatten the input images to 1D vector\n",
        "    for _ in range(n_hidden):  # Hidden layers\n",
        "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))  # Output layer\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Hyperparameter tuning using RandomSearch\n",
        "random_search_tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=5,\n",
        "    overwrite=True,\n",
        "    directory=\"my_mnist\",\n",
        "    project_name=\"random_search\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Fit the model with the RandomSearch tuner\n",
        "random_search_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# Get the top 3 models from the RandomSearch\n",
        "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
        "best_model = top3_models[0]\n",
        "\n",
        "# Get the best hyperparameters of the best model\n",
        "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\n",
        "print(top3_params[0].values)  # Best hyperparameter values\n",
        "\n",
        "# Get trial summary for the best trial\n",
        "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
        "print(best_trial.summary())\n",
        "print(best_trial.metrics.get_last_value(\"val_accuracy\"))\n",
        "\n",
        "# Training the best model on the full training data\n",
        "best_model.fit(X_train, y_train, epochs=10)\n",
        "test_loss, test_accuracy = best_model.evaluate(X_valid, y_valid)\n",
        "print(f\"Test accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yQEFMKvqhk7",
        "outputId": "ad339983-6cd6-4647-ec5c-0465fc501017"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 01m 11s]\n",
            "val_accuracy: 0.8476999998092651\n",
            "\n",
            "Best val_accuracy So Far: 0.9652000069618225\n",
            "Total elapsed time: 00h 06m 06s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_hidden': 4, 'n_neurons': 74, 'learning_rate': 0.00905127409782462, 'optimizer': 'adam'}\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "n_hidden: 4\n",
            "n_neurons: 74\n",
            "learning_rate: 0.00905127409782462\n",
            "optimizer: adam\n",
            "Score: 0.9652000069618225\n",
            "None\n",
            "0.9652000069618225\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.1533\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.1162\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9697 - loss: 0.1367\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.1204\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9718 - loss: 0.1142\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.1131\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9761 - loss: 0.1187\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0853\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.1090\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.1005\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.2439\n",
            "Test accuracy: 0.9624999761581421\n"
          ]
        }
      ]
    }
  ]
}