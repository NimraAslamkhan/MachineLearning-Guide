{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c5259875a5b04683973fc275ae639552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_196555e41ea74dc7b60a97c6f83228f1",
              "IPY_MODEL_0c884618f4164da592f5085310b69d6a",
              "IPY_MODEL_577295745e8f4db4b56b17b3856a181b"
            ],
            "layout": "IPY_MODEL_09c63e9a237f4839a33d0c514d0d9f3c"
          }
        },
        "196555e41ea74dc7b60a97c6f83228f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90349dcc28954f13b4af25440f735445",
            "placeholder": "​",
            "style": "IPY_MODEL_f5a8480376bb458ca860c8e8193b2c7a",
            "value": "Dl Completed...: 100%"
          }
        },
        "0c884618f4164da592f5085310b69d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_157d450784f840adb09f1518b1cd8de8",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_536ffd66c53e4ea591930f86ded9ca26",
            "value": 5
          }
        },
        "577295745e8f4db4b56b17b3856a181b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2e49de29a244de1b0a357161a224412",
            "placeholder": "​",
            "style": "IPY_MODEL_a16d6a7af4b34dca9d5d095c9b9724e6",
            "value": " 5/5 [00:00&lt;00:00, 10.19 file/s]"
          }
        },
        "09c63e9a237f4839a33d0c514d0d9f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90349dcc28954f13b4af25440f735445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a8480376bb458ca860c8e8193b2c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "157d450784f840adb09f1518b1cd8de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536ffd66c53e4ea591930f86ded9ca26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2e49de29a244de1b0a357161a224412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a16d6a7af4b34dca9d5d095c9b9724e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Dataset\n",
        "From a Tensor"
      ],
      "metadata": {
        "id": "dpuOieZIuyHk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdVb3c3ztbZ0",
        "outputId": "f2fbdf8d-8ced-4a57-f524-2474edaca8d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a dataset from a tensor\n",
        "X = tf.range(10)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "\n",
        "# Iterating over the dataset\n",
        "for item in dataset:\n",
        "    print(item)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a Nested Structure"
      ],
      "metadata": {
        "id": "pOhhFy3Su2oF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset with nested structures\n",
        "X_nested = {\"a\": ([1, 2, 3], [4, 5, 6]), \"b\": [7, 8, 9]}\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_nested)\n",
        "\n",
        "# Iterating over the dataset\n",
        "for item in dataset:\n",
        "    print(item)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d38w8L_u7TO",
        "outputId": "710c2f35-d7d5-4816-bf2e-b504bcb3b520"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=4>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=7>}\n",
            "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=8>}\n",
            "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=6>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=9>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chaining Transformations\n",
        "Transformations like repeat(), batch(), and map() can be chained for efficient preprocessing.\n",
        "\n",
        "Example: Repeat and Batch"
      ],
      "metadata": {
        "id": "3kQ542gIu_z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat the dataset 3 times and batch it\n",
        "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
        "dataset = dataset.repeat(3).batch(7)\n",
        "\n",
        "# Iterating over the transformed dataset\n",
        "for item in dataset:\n",
        "    print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbBToQ3qvGNO",
        "outputId": "9eed66bc-8de2-46ec-a92d-249860be9240"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: Applying a Mapping Function"
      ],
      "metadata": {
        "id": "EsZ0cCKbvJwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply a transformation (e.g., multiplying by 2)\n",
        "dataset = dataset.map(lambda x: x * 2)\n",
        "\n",
        "for item in dataset:\n",
        "    print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2IM7cnivN70",
        "outputId": "4fa84082-abe5-4c2c-9c80-c4cf5dbbdda3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: Filtering Data"
      ],
      "metadata": {
        "id": "5QMxjIdivQYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter items based on a condition (sum > 50)\n",
        "dataset = dataset.filter(lambda x: tf.reduce_sum(x) > 50)\n",
        "\n",
        "for item in dataset:\n",
        "    print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2jWDSRxvT__",
        "outputId": "80da5ff0-5760-4f28-b4a7-54633cfc6e35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: Taking a Few Items"
      ],
      "metadata": {
        "id": "cIzWjcjBvXCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take only the first 2 items\n",
        "for item in dataset.take(2):\n",
        "    print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utbGYroova_Y",
        "outputId": "d821c4ea-3ec2-4dab-c813-f251daabbf2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shuffling the Data\n",
        "Shuffling ensures that the dataset instances are independent and identically distributed (IID).\n",
        "\n",
        "Simple Shuffling"
      ],
      "metadata": {
        "id": "bKF3PReeve7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the dataset with a buffer size of 4\n",
        "dataset = tf.data.Dataset.range(10).repeat(2)\n",
        "dataset = dataset.shuffle(buffer_size=4, seed=42).batch(7)\n",
        "\n",
        "for item in dataset:\n",
        "    print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_u3f94OvjPq",
        "outputId": "b0826d36-d1dc-47dc-a9ad-c78e20ee45de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 4 2 3 5 0 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 8 2 0 3 1 4], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 7 9 6 7 8], shape=(6,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Shuffling for Large Datasets\n",
        "For datasets that do not fit in memory:\n",
        "\n",
        "Shuffle the source data itself (e.g., using Linux's shuf command).\n",
        "Split data into multiple files.\n",
        "Use tf.data to read files randomly, interleave records, and add shuffling buffers."
      ],
      "metadata": {
        "id": "fk_AZgVUvmMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Example: Replace with actual paths or glob patterns\n",
        "file_paths = [\"/content/sample_data/california_housing_test.csv\"]\n",
        "\n",
        "# Verify that files exist\n",
        "for path in file_paths:\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"File does not exist: {path}\")\n",
        "\n",
        "# Create a dataset from the list of files\n",
        "dataset = tf.data.Dataset.list_files(file_paths)\n",
        "\n",
        "# Interleave lines from files\n",
        "dataset = dataset.interleave(\n",
        "    lambda file: tf.data.TextLineDataset(file),\n",
        "    cycle_length=3,  # Number of files to read concurrently\n",
        "    block_length=1\n",
        ")\n",
        "\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.shuffle(buffer_size=1000)  # Adjust buffer size based on memory\n",
        "\n",
        "# Inspect the dataset\n",
        "for item in dataset.take(5):\n",
        "    print(item.numpy().decode(\"utf-8\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2PvTAQLvujR",
        "outputId": "ccc935f5-126a-4bb0-b52b-d68fea453b31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-119.010000,35.380000,52.000000,114.000000,26.000000,158.000000,26.000000,1.075000,67500.000000\n",
            "-122.140000,40.070000,31.000000,2053.000000,465.000000,1193.000000,447.000000,1.492300,44400.000000\n",
            "-118.370000,33.950000,5.000000,6955.000000,2062.000000,3591.000000,1566.000000,3.111000,247600.000000\n",
            "-117.810000,33.820000,22.000000,2898.000000,335.000000,1057.000000,324.000000,10.811100,500001.000000\n",
            "-117.920000,34.120000,32.000000,2552.000000,576.000000,2161.000000,548.000000,2.945900,144400.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interleaving File Data\n",
        "Interleave: Use the interleave() method to read and combine lines from multiple files simultaneously. This improves parallelism:"
      ],
      "metadata": {
        "id": "xue0jig2wjBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = filepath_dataset.interleave(\n",
        "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "    cycle_length=n_readers\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZAqNXJdCyH_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data\n",
        "Parsing CSV Lines: Convert raw CSV lines into feature tensors"
      ],
      "metadata": {
        "id": "495oORdHyM3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_csv_line(line):\n",
        "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
        "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
        "    return tf.stack(fields[:-1]), tf.stack(fields[-1:])\n"
      ],
      "metadata": {
        "id": "wwJjgyXZyTu-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling Features: Normalize the features using precomputed mean and standard deviation"
      ],
      "metadata": {
        "id": "2YUNA88byWj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(line):\n",
        "    x, y = parse_csv_line(line)\n",
        "    return (x - X_mean) / X_std, y\n"
      ],
      "metadata": {
        "id": "qmJkD02ByZZY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Efficient Input Pipeline\n",
        "Combine everything into a reusable function:"
      ],
      "metadata": {
        "id": "Y6hkg9G0ybny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_reader_dataset(filepaths, n_readers=5, n_read_threads=None,\n",
        "                       n_parse_threads=5, shuffle_buffer_size=10_000,\n",
        "                       batch_size=32, seed=42):\n",
        "    dataset = tf.data.Dataset.list_files(filepaths, seed=seed)\n",
        "    dataset = dataset.interleave(\n",
        "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size, seed=seed)\n",
        "    return dataset.batch(batch_size).prefetch(1)\n"
      ],
      "metadata": {
        "id": "cQp9QVVuyptA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using with Keras\n",
        "Create datasets for training, validation, and testing:"
      ],
      "metadata": {
        "id": "WHG-y3cAyu1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = csv_reader_dataset(train_filepaths)\n",
        "valid_set = csv_reader_dataset(valid_filepaths)\n",
        "test_set = csv_reader_dataset(test_filepaths)\n"
      ],
      "metadata": {
        "id": "m1wdPEbMy12W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([...])\n",
        "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
        "model.fit(train_set, validation_data=valid_set, epochs=5)\n",
        "test_mse = model.evaluate(test_set)\n"
      ],
      "metadata": {
        "id": "A3APNuEoy9If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For predictions\n",
        "new_set = test_set.take(3)  # Get 3 new samples\n",
        "y_pred = model.predict(new_set)\n"
      ],
      "metadata": {
        "id": "9dnI2oM8zCuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFRecord Basics\n",
        "A TFRecord file stores binary data, consisting of:\n",
        "\n",
        "A length field (size of each record)\n",
        "A CRC checksum for integrity verification\n",
        "The data payload (actual record content)\n",
        "Writing TFRecord Files"
      ],
      "metadata": {
        "id": "BEZWcvHw02JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
        "    f.write(b\"This is the first record\")\n",
        "    f.write(b\"And this is the second record\")\n"
      ],
      "metadata": {
        "id": "NUd1m63WzF39"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading TFRecord Files"
      ],
      "metadata": {
        "id": "mbF8FLOo0_EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = [\"my_data.tfrecord\"]\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "\n",
        "for item in dataset:\n",
        "    print(item)  # Outputs tf.Tensor objects\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygQIVgBN1AFv",
        "outputId": "fb750947-1208-44ff-e900-adae13a99fcc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Compressed TFRecord Files\n",
        "TFRecord files can be compressed using formats like GZIP for network efficiency.\n",
        "\n",
        "Writing Compressed TFRecords"
      ],
      "metadata": {
        "id": "162K4qkq1IOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "with tf.io.TFRecordWriter(\"compressed.tfrecord\", options) as f:\n",
        "    f.write(b\"Compressed data\")\n"
      ],
      "metadata": {
        "id": "e4-VoR721K2o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.TFRecordDataset([\"compressed.tfrecord\"], compression_type=\"GZIP\")\n"
      ],
      "metadata": {
        "id": "6tNHK1K51NTw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Protobuf Introduction\n",
        "Definition\n",
        "Protobuf (Protocol Buffers) is a binary serialization format widely used in TFRecord files. A protobuf schema defines structured data using .proto files, such as"
      ],
      "metadata": {
        "id": "L3nV4rfB1TXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "syntax = \"proto3\";\n",
        "\n",
        "message Person {\n",
        "  string name = 1;\n",
        "  int32 id = 2;\n",
        "  repeated string email = 3;\n",
        "}\n"
      ],
      "metadata": {
        "id": "HCvYb0lz1fWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Protobuf in Python\n",
        "Once compiled with protoc, the generated Python access classes can be used to create, manipulate, and serialize objects"
      ],
      "metadata": {
        "id": "06nZ1vXz1gRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from person_pb2 import Person\n",
        "\n",
        "person = Person(name=\"Alice\", id=123, email=[\"a@b.com\", \"c@d.com\"])\n",
        "serialized = person.SerializeToString()  # Serialize to binary\n",
        "print(serialized)\n",
        "\n",
        "# Deserialize\n",
        "person2 = Person()\n",
        "person2.ParseFromString(serialized)\n",
        "print(person2)\n"
      ],
      "metadata": {
        "id": "h6RIbbh61mAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  TensorFlow Protobufs\n",
        "The Example protobuf is commonly used in TFRecord files for datasets. Its structure is:\n",
        "\n",
        "Features: A mapping of feature names to values, where each value is:\n",
        "A BytesList (e.g., strings)\n",
        "A FloatList (e.g., floats)\n",
        "An Int64List (e.g., integers)"
      ],
      "metadata": {
        "id": "0ie0jV8B1ofR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.train import BytesList, FloatList, Int64List, Feature, Features, Example\n",
        "\n",
        "example = Example(\n",
        "    features=Features(\n",
        "        feature={\n",
        "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
        "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
        "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", b\"c@d.com\"])),\n",
        "        }\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "cR1yeIdt1t0M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing Example Protobufs to TFRecord"
      ],
      "metadata": {
        "id": "v-WO4W4z1xVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.io.TFRecordWriter(\"example.tfrecord\") as f:\n",
        "    f.write(example.SerializeToString())\n"
      ],
      "metadata": {
        "id": "JiETXNbn11UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading and Parsing Protobufs\n",
        "To parse serialized examples, define a feature description and use tf.io.parse_single_example()"
      ],
      "metadata": {
        "id": "8PdCKdtM13Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_description = {\n",
        "    \"name\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"id\": tf.io.FixedLenFeature([], tf.int64),\n",
        "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
        "}\n",
        "\n",
        "def parse_example(serialized):\n",
        "    return tf.io.parse_single_example(serialized, feature_description)\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(\"example.tfrecord\").map(parse_example)\n",
        "\n",
        "for item in dataset:\n",
        "    print(item[\"name\"].numpy())  # Example: b'Alice'\n"
      ],
      "metadata": {
        "id": "pE_7GiSl2L7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Nested Data with SequenceExample\n",
        "For hierarchical data (e.g., text documents with sentences), use the SequenceExample protobuf, which supports:\n",
        "\n",
        "### Contextual features:\n",
        "Metadata like document title or author\n",
        "### Feature lists:\n",
        "Nested lists such as sentences or comments"
      ],
      "metadata": {
        "id": "2nxfydxV2Peb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message SequenceExample {\n",
        "  Features context = 1;\n",
        "  FeatureLists feature_lists = 2;\n",
        "}\n"
      ],
      "metadata": {
        "id": "WVv2Sk6j2bYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.train import FeatureList, FeatureLists, SequenceExample\n",
        "\n",
        "sequence_example = SequenceExample(\n",
        "    context=Features(\n",
        "        feature={\n",
        "            \"title\": Feature(bytes_list=BytesList(value=[b\"My Document\"])),\n",
        "        }\n",
        "    ),\n",
        "    feature_lists=FeatureLists(\n",
        "        feature_list={\n",
        "            \"sentences\": FeatureList(\n",
        "                feature=[\n",
        "                    Feature(bytes_list=BytesList(value=[b\"Hello\", b\"world\"])),\n",
        "                    Feature(bytes_list=BytesList(value=[b\"This\", b\"is\", b\"TensorFlow\"])),\n",
        "                ]\n",
        "            )\n",
        "        }\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "WvRRJzzi2g_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serializing and Writing"
      ],
      "metadata": {
        "id": "vq65Qxel2mD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.io.TFRecordWriter(\"sequence.tfrecord\") as f:\n",
        "    f.write(sequence_example.SerializeToString())\n"
      ],
      "metadata": {
        "id": "TtN0lOFs2nCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing Images and Tensors\n",
        "You can store images or tensors in TFRecords using BytesList."
      ],
      "metadata": {
        "id": "h5mR6gYc2r2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.io.encode_jpeg(tf.random.uniform([128, 128, 3], maxval=255, dtype=tf.int32))\n",
        "example = Example(\n",
        "    features=Features(\n",
        "        feature={\"image\": Feature(bytes_list=BytesList(value=[image.numpy()]))}\n",
        "    )\n",
        ")\n",
        "\n",
        "with tf.io.TFRecordWriter(\"images.tfrecord\") as f:\n",
        "    f.write(example.SerializeToString())\n"
      ],
      "metadata": {
        "id": "N4ipjHHC2vNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading and Decoding"
      ],
      "metadata": {
        "id": "6MZbEGo92zMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_image(serialized):\n",
        "    features = {\"image\": tf.io.FixedLenFeature([], tf.string)}\n",
        "    parsed = tf.io.parse_single_example(serialized, features)\n",
        "    return tf.io.decode_jpeg(parsed[\"image\"])\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(\"images.tfrecord\").map(parse_image)\n"
      ],
      "metadata": {
        "id": "1eepIvBv25MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Preprocessing Layers\n",
        "Normalization Layer\n",
        "\n",
        "Standardizes numerical features by centering them at zero with a unit standard deviation."
      ],
      "metadata": {
        "id": "B7ygW1lr5QDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_layer = tf.keras.layers.Normalization()\n",
        "norm_layer.adapt(X_train)\n",
        "model = tf.keras.Sequential([norm_layer, tf.keras.layers.Dense(1)])\n"
      ],
      "metadata": {
        "id": "n3UHgvD85TyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess before training"
      ],
      "metadata": {
        "id": "Sj3_XuB85V0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_layer.adapt(X_train)\n",
        "X_train_scaled = norm_layer(X_train)\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n"
      ],
      "metadata": {
        "id": "ZlVgYYaG5ZIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discretization Layer\n",
        "Transforms numerical features into categorical ones by binning values"
      ],
      "metadata": {
        "id": "-iYSR9qh5eOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discretize_layer = tf.keras.layers.Discretization(bin_boundaries=[18, 50])\n",
        "age_categories = discretize_layer(age_data)\n"
      ],
      "metadata": {
        "id": "8o_cotD15bPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CategoryEncoding Layer\n",
        "\n",
        "Encodes integer categories into:\n",
        "One-hot: Binary vectors for each category.\n",
        "Multi-hot: Multi-category occurrences.\n",
        "Count: Frequency of categories."
      ],
      "metadata": {
        "id": "q3PE9BLQ5lG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3)\n",
        "one_hot_encoded = onehot_layer(age_categories)\n"
      ],
      "metadata": {
        "id": "3pQnoMUl5h0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StringLookup Layer\n",
        "Encodes text categories into integers or one-hot vectors.\n"
      ],
      "metadata": {
        "id": "2j81lDjV5tH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cities = [\"Paris\", \"Auckland\", \"San Francisco\"]\n",
        "str_lookup_layer = tf.keras.layers.StringLookup(output_mode=\"one_hot\")\n",
        "str_lookup_layer.adapt(cities)\n",
        "encoded = str_lookup_layer([\"Paris\", \"Auckland\"])\n"
      ],
      "metadata": {
        "id": "_uxoFSXB5puZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Preprocessing Layers\n",
        "If a suitable layer isn't available, you can implement a custom one"
      ],
      "metadata": {
        "id": "wgFUrohG5xkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNormalization(tf.keras.layers.Layer):\n",
        "    def adapt(self, X):\n",
        "        self.mean_ = np.mean(X, axis=0)\n",
        "        self.std_ = np.std(X, axis=0)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return (inputs - self.mean_) / (self.std_ + tf.keras.backend.epsilon())\n"
      ],
      "metadata": {
        "id": "SoG6RD_H52kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integration with tf.data API\n",
        "Preprocessing layers can be adapted to datasets using"
      ],
      "metadata": {
        "id": "H3U3wLBC570V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(lambda X, y: (norm_layer(X), y))\n"
      ],
      "metadata": {
        "id": "Gq_10Z-654ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing with TextVectorization"
      ],
      "metadata": {
        "id": "9rg52C2n5_Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Training data\n",
        "train_data = [\"To be\", \"!(to be)\", \"That's the question\", \"Be, be, be.\"]\n",
        "\n",
        "# Initialize and adapt the TextVectorization layer\n",
        "text_vec_layer = tf.keras.layers.TextVectorization(output_mode=\"tf_idf\")\n",
        "text_vec_layer.adapt(train_data)\n",
        "\n",
        "# Transform input sentences\n",
        "result = text_vec_layer([\"Be good!\", \"Question: be or be?\"])\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftFAsj9C7XqL",
        "outputId": "02012f43-0d98-4ce8-d25a-cd2955437e7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.96725637 0.6931472  0.         0.         0.         0.        ]\n",
            " [0.96725637 1.3862944  0.         0.         0.         1.0986123 ]], shape=(2, 6), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pretrained Language Model Components"
      ],
      "metadata": {
        "id": "5ctww-VV7diz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the pretrained module\n",
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\")\n",
        "\n",
        "# Encode sentences\n",
        "sentence_embeddings = hub_layer(tf.constant([\"To be\", \"Not to be\"]))\n",
        "print(sentence_embeddings.numpy().round(2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWPqO-g37eXh",
        "outputId": "4d5daca3-ab4a-47dd-f9a0-ac831a0a8ea6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.25  0.28  0.01  0.1   0.14  0.16  0.25  0.02  0.07  0.13 -0.19  0.06\n",
            "  -0.04 -0.07  0.   -0.08 -0.14 -0.16  0.02 -0.24  0.16 -0.16 -0.03  0.03\n",
            "  -0.14  0.03 -0.09 -0.04 -0.14 -0.19  0.07  0.15  0.18 -0.23 -0.07 -0.08\n",
            "   0.01 -0.01  0.09  0.14 -0.03  0.03  0.08  0.1  -0.01 -0.03 -0.07 -0.1\n",
            "   0.05  0.31]\n",
            " [-0.2   0.2  -0.08  0.02  0.19  0.05  0.22 -0.09  0.02  0.19 -0.02 -0.14\n",
            "  -0.2  -0.04  0.01 -0.07 -0.22 -0.1   0.16 -0.44  0.31 -0.1   0.23  0.15\n",
            "  -0.05  0.15 -0.13 -0.04 -0.08 -0.16 -0.1   0.13  0.13 -0.18 -0.04  0.03\n",
            "  -0.1  -0.07  0.07  0.03 -0.08  0.02  0.05  0.07 -0.14 -0.1  -0.18 -0.13\n",
            "  -0.04  0.15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Preprocessing Example"
      ],
      "metadata": {
        "id": "ax8mOQTR7lGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_sample_images\n",
        "\n",
        "# Load sample images\n",
        "images = load_sample_images()[\"images\"]\n",
        "\n",
        "# Center crop images\n",
        "crop_image_layer = tf.keras.layers.CenterCrop(height=100, width=100)\n",
        "cropped_images = crop_image_layer(images)\n",
        "\n",
        "# Rescale images\n",
        "rescale_layer = tf.keras.layers.Rescaling(scale=1.0/255)\n",
        "rescaled_images = rescale_layer(cropped_images)\n"
      ],
      "metadata": {
        "id": "mhrwpcnZ7l0r"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation Example\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# Apply augmentation to images\n",
        "augmented_images = data_augmentation(cropped_images)\n"
      ],
      "metadata": {
        "id": "mTx2qT5q7mR-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The TensorFlow Datasets Project"
      ],
      "metadata": {
        "id": "2O7QhHJw9Mb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset, split into training, validation, and test sets\n",
        "train_set, valid_set, test_set = tfds.load(\n",
        "    name=\"mnist\",\n",
        "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
        "    as_supervised=True  # Ensures the dataset returns (image, label) tuples\n",
        ")\n",
        "\n",
        "# Prepare the datasets\n",
        "train_set = train_set.shuffle(buffer_size=10_000, seed=42).batch(32).prefetch(1)\n",
        "valid_set = valid_set.batch(32).cache()\n",
        "test_set = test_set.batch(32).cache()\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define a simple neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")  # Output layer with 10 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",  # Suitable loss function for integer labels\n",
        "    optimizer=\"nadam\",  # Nesterov-accelerated Adaptive Moment Estimation\n",
        "    metrics=[\"accuracy\"]  # Track accuracy during training\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_set,\n",
        "    validation_data=valid_set,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_set)\n",
        "\n",
        "# Print test results\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364,
          "referenced_widgets": [
            "c5259875a5b04683973fc275ae639552",
            "196555e41ea74dc7b60a97c6f83228f1",
            "0c884618f4164da592f5085310b69d6a",
            "577295745e8f4db4b56b17b3856a181b",
            "09c63e9a237f4839a33d0c514d0d9f3c",
            "90349dcc28954f13b4af25440f735445",
            "f5a8480376bb458ca860c8e8193b2c7a",
            "157d450784f840adb09f1518b1cd8de8",
            "536ffd66c53e4ea591930f86ded9ca26",
            "a2e49de29a244de1b0a357161a224412",
            "a16d6a7af4b34dca9d5d095c9b9724e6"
          ]
        },
        "id": "4yb4U4WL9Snq",
        "outputId": "531733bb-8459-4e50-9f47-baf90dc58092"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5259875a5b04683973fc275ae639552"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 19.2089 - val_accuracy: 0.8690 - val_loss: 6.2683\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8770 - loss: 5.8573 - val_accuracy: 0.8858 - val_loss: 5.8402\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 5.2617 - val_accuracy: 0.8892 - val_loss: 5.1971\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 4.9461 - val_accuracy: 0.8847 - val_loss: 5.3869\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 4.8653 - val_accuracy: 0.8782 - val_loss: 5.8640\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 5.4981\n",
            "Test Loss: 5.6026\n",
            "Test Accuracy: 0.8835\n"
          ]
        }
      ]
    }
  ]
}