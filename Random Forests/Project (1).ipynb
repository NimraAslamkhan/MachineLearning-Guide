{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Below is a comprehensive project that covers the topics you've provided, structured to demonstrate different ensemble methods in machine learning, including Bagging, Random Forest, Boosting, and Stacking classifiers. The project uses the scikit-learn library to implement these concepts on a synthetic dataset, specifically the \"moons\" dataset for classification tasks.\n",
        "\n",
        "## Project Structure\n",
        "### Import Libraries\n",
        "### Generate Dataset\n",
        "### Train-Test Split\n",
        "### Bagging Classifier\n",
        "### Random Forest Classifier\n",
        "### AdaBoost Classifier\n",
        "### Gradient Boosting Regressor\n",
        "### Stacking Classifier\n",
        "### Results and Feature Importances\n"
      ],
      "metadata": {
        "id": "733Vk625lQYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Me3xJquElAxX"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_moons, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingRegressor, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Generate Dataset\n",
        "# Generating the moons dataset for classification\n",
        "X, y = make_moons(n_samples=500, noise=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "oufeL89plrb1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "f-4CLeRBlvsY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Bagging Classifier\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_depth=3),  # Removed base_estimator keyword\n",
        "    n_estimators=500,\n",
        "    max_samples=0.8,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "# Bagging Classifier Score\n",
        "bagging_score = bag_clf.score(X_test, y_test)\n",
        "print(\"Bagging Classifier Score:\", bagging_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "goaapWiSmOHN",
        "outputId": "93de67ef-36af-4c74-c864-1ff492130802"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Score: 0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Random Forest Classifier\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rnd_clf.predict(X_test)\n",
        "\n",
        "# Random Forest Classifier Score\n",
        "rf_score = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest Classifier Score:\", rf_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4UJ1MkzzmoSC",
        "outputId": "9a67b9d8-4701-46b6-9a85-ab84d5405191"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Score: 0.912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. AdaBoost Classifier\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1),  # Changed base_estimator to estimator\n",
        "    n_estimators=30,\n",
        "    learning_rate=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "ada_clf.fit(X_train, y_train)\n",
        "\n",
        "# AdaBoost Classifier Score\n",
        "ada_score = ada_clf.score(X_test, y_test)\n",
        "print(\"AdaBoost Classifier Score:\", ada_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "axYnztTPnNKz",
        "outputId": "26842f34-cc2e-4c38-f483-46b99d87dc34"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Score: 0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Stacking Classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', DecisionTreeClassifier(max_depth=3, random_state=42)),\n",
        "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "        ('svc', DecisionTreeClassifier(max_depth=1, random_state=42))\n",
        "    ],\n",
        "    final_estimator=RandomForestClassifier(random_state=43),\n",
        "    cv=5  # number of cross-validation folds\n",
        ")\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Stacking Classifier Score\n",
        "stacking_score = stacking_clf.score(X_test, y_test)\n",
        "print(\"Stacking Classifier Score:\", stacking_score)\n",
        "\n",
        "# 9. Feature Importances (Random Forest)\n",
        "# Displaying feature importances for Random Forest\n",
        "feature_importances = rnd_clf.feature_importances_\n",
        "print(\"Random Forest Feature Importances:\")\n",
        "for score, name in zip(feature_importances, [\"Feature 1\", \"Feature 2\"]):\n",
        "    print(round(score, 2), name)\n",
        "\n",
        "# 10. Conclusion\n",
        "print(\"\\nConclusion: This project demonstrates various ensemble methods in cl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kgMtTLe3nPAU",
        "outputId": "393ac11f-eb91-4c7a-a4ad-34e31d46eb3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Score: 0.896\n",
            "Random Forest Feature Importances:\n",
            "0.42 Feature 1\n",
            "0.58 Feature 2\n",
            "\n",
            "Conclusion: This project demonstrates various ensemble methods in cl\n"
          ]
        }
      ]
    }
  ]
}